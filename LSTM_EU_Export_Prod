{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LSTM for Extra-Eu Exports\n\nThis notebook is used to test LSTM model for the Statistics Awards 3 for Extra-Eu Export of Goods. It get the data from Eurostat for all EU countries. \n\n**This notebook is from Kaggle.**\n","metadata":{"_uuid":"f5c6941f-4660-4f3c-bbc6-611b46e765e2","_cell_guid":"0a1beaa7-c43c-4104-89f8-a80a6ca1e3d7","trusted":true}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","metadata":{"_uuid":"4e219d17-be80-438e-a965-9412874736f0","_cell_guid":"d7d0b5ab-6022-4e08-af7e-076b197f2af4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:22.051158Z","iopub.execute_input":"2024-12-27T19:15:22.0515Z","iopub.status.idle":"2024-12-27T19:15:22.409972Z","shell.execute_reply.started":"2024-12-27T19:15:22.051462Z","shell.execute_reply":"2024-12-27T19:15:22.409134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Import Python packages and set up","metadata":{"_uuid":"b709bb19-3ba8-4267-b274-4392e65472f8","_cell_guid":"4796b168-503c-4cb2-a2ea-28783e5973e4","trusted":true}},{"cell_type":"code","source":"fcst_mon = pd.Timestamp('Dec, 2024')\nfcst_mon","metadata":{"_uuid":"3f2f0444-25bc-4181-b158-8ffba50dc923","_cell_guid":"824eda05-3d91-4625-841a-3bac84f4802c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:22.410929Z","iopub.execute_input":"2024-12-27T19:15:22.411276Z","iopub.status.idle":"2024-12-27T19:15:22.41861Z","shell.execute_reply.started":"2024-12-27T19:15:22.411252Z","shell.execute_reply":"2024-12-27T19:15:22.417822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Backgroud\n\nThe notebook is for the Statistics-awards Round 3. More information is available at\nhttps://statistics-awards.eu/nowcasting/. Most of the data are available from Eurostat: \nhttps://ec.europa.eu/eurostat/databrowser/view/nrg_cb_oilm__custom_7625136/default/table?lang=en.\n\nExtra-EU exports:\n\nTrade flows cover all goods entering (imports) or leaving (exports) the statistical territories of the EU Member States. Intra-EU refers to all transactions occurring within the EU. \n\nThe task of each team is to nowcast the values for all 6 months between October 2024 and March 2025.","metadata":{"_uuid":"2c10dc65-4166-4b97-9a38-825714bdfe18","_cell_guid":"cb8f00dc-6202-47f0-9704-5b3c2481baa0","trusted":true}},{"cell_type":"code","source":"# import other packages and set up figures\nfrom datetime import datetime\n\nstarttime = datetime.now()\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer, SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.multioutput import RegressorChain\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom statsmodels.tsa.deterministic import DeterministicTerm, Seasonality, TimeTrend\nfrom xgboost import XGBRegressor\n\nfrom warnings import simplefilter\n# Ignore warnings\nsimplefilter(\"ignore\")\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\n\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(11, 4),\n    titlesize=18,\n    titleweight='bold',\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n)\n\nprint(\"setup complete.\")","metadata":{"_uuid":"3a12bc30-f497-42b2-8540-ab2daa044847","_cell_guid":"0f49e100-7fb5-47d4-a647-71408ab190c6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:22.420329Z","iopub.execute_input":"2024-12-27T19:15:22.420612Z","iopub.status.idle":"2024-12-27T19:15:23.853791Z","shell.execute_reply.started":"2024-12-27T19:15:22.420582Z","shell.execute_reply":"2024-12-27T19:15:23.852991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Get data from Eurostat and clean the data\n\nIt is possible to use API to obtain data from Eurostat. We use here the Python package \"eurostat\" to facilitate this process.","metadata":{"_uuid":"33c7b820-3974-4213-b1df-e1b8eaeb930d","_cell_guid":"b9f189f0-c392-47ff-9ca2-8402c2fca1dc","trusted":true}},{"cell_type":"code","source":"# Install the package\n!pip install eurostat","metadata":{"_uuid":"3c6f833c-8353-46d7-9787-3eb75357151d","_cell_guid":"b0dca3bd-c836-447b-b305-7c9b9b082380","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:23.855197Z","iopub.execute_input":"2024-12-27T19:15:23.855543Z","iopub.status.idle":"2024-12-27T19:15:29.414209Z","shell.execute_reply.started":"2024-12-27T19:15:23.85552Z","shell.execute_reply":"2024-12-27T19:15:29.413031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import eurostat as estat","metadata":{"_uuid":"ac9b9330-84f6-4e21-ac3c-0fcd8a7f533e","_cell_guid":"4471444c-4a81-4fe9-8183-501afeda31c6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:29.415357Z","iopub.execute_input":"2024-12-27T19:15:29.415616Z","iopub.status.idle":"2024-12-27T19:15:29.560166Z","shell.execute_reply.started":"2024-12-27T19:15:29.415593Z","shell.execute_reply":"2024-12-27T19:15:29.559163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"toc_df = estat.get_toc_df()\n#toc_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:29.561215Z","iopub.execute_input":"2024-12-27T19:15:29.561508Z","iopub.status.idle":"2024-12-27T19:15:34.013446Z","shell.execute_reply.started":"2024-12-27T19:15:29.56147Z","shell.execute_reply":"2024-12-27T19:15:34.012412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estat.subset_toc_df(toc_df, \"international trade\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:34.014608Z","iopub.execute_input":"2024-12-27T19:15:34.014993Z","iopub.status.idle":"2024-12-27T19:15:34.056757Z","shell.execute_reply.started":"2024-12-27T19:15:34.014956Z","shell.execute_reply":"2024-12-27T19:15:34.055927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The code of Export of Goods from the Eurostat API\ncode1= \"EI_ETEU27_2020_M\"","metadata":{"_uuid":"c7f36fe8-1ab0-438e-baf9-7b8df0131da2","_cell_guid":"91073278-2f52-4c15-8690-13cf821319d3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:34.059201Z","iopub.execute_input":"2024-12-27T19:15:34.059602Z","iopub.status.idle":"2024-12-27T19:15:34.063264Z","shell.execute_reply.started":"2024-12-27T19:15:34.059575Z","shell.execute_reply":"2024-12-27T19:15:34.062448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#help(estat.get_pars)","metadata":{"_uuid":"b239a037-95e1-4cbe-97cd-bf89641e7690","_cell_guid":"c6e2d76e-45aa-4419-b40b-c234ebb3e2c2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:34.065273Z","iopub.execute_input":"2024-12-27T19:15:34.065528Z","iopub.status.idle":"2024-12-27T19:15:34.079822Z","shell.execute_reply.started":"2024-12-27T19:15:34.065504Z","shell.execute_reply":"2024-12-27T19:15:34.078905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estat.get_pars(code1)","metadata":{"_uuid":"6be329d6-e1a0-4df5-a546-c1fe688a4b61","_cell_guid":"3b32b14f-3220-4de5-b8b8-393ec049f139","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:34.080833Z","iopub.execute_input":"2024-12-27T19:15:34.081193Z","iopub.status.idle":"2024-12-27T19:15:34.798577Z","shell.execute_reply.started":"2024-12-27T19:15:34.08115Z","shell.execute_reply":"2024-12-27T19:15:34.797674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estat.get_par_values(code1,\"stk_flow\")","metadata":{"_uuid":"7fa23fbb-526a-491a-94bc-e5f07d991db0","_cell_guid":"1b15d5b0-e4cf-4744-8637-ac223c85e2ff","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:34.79952Z","iopub.execute_input":"2024-12-27T19:15:34.799903Z","iopub.status.idle":"2024-12-27T19:15:35.542891Z","shell.execute_reply.started":"2024-12-27T19:15:34.799867Z","shell.execute_reply":"2024-12-27T19:15:35.541903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estat.get_par_values(code1,\"partner\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:35.543923Z","iopub.execute_input":"2024-12-27T19:15:35.544247Z","iopub.status.idle":"2024-12-27T19:15:36.27165Z","shell.execute_reply.started":"2024-12-27T19:15:35.544219Z","shell.execute_reply":"2024-12-27T19:15:36.270066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estat.get_par_values(code1,\"indic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:36.272581Z","iopub.execute_input":"2024-12-27T19:15:36.272901Z","iopub.status.idle":"2024-12-27T19:15:36.988994Z","shell.execute_reply.started":"2024-12-27T19:15:36.272874Z","shell.execute_reply":"2024-12-27T19:15:36.9881Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extra-EU Exp\n\n\"stk_flow\":\"EXP\",\"partner\":\"EXT_EU27_2020\"","metadata":{}},{"cell_type":"code","source":"# Restrict to some parameters to select the data needed\nmy_pars = {\"freq\": \"M\",\"stk_flow\":\"EXP\",\"partner\":\"EXT_EU27_2020\",\"indic\":\"ET-T\",\"unit\":\"MIO-EUR-NSA\",\"startPeriod\":\"2010-01\"}","metadata":{"_uuid":"facaff83-b0e9-4dc5-8152-f7b76fa1f6fd","_cell_guid":"d94b74f7-e7b8-4b8c-a0cf-0da9ba155e86","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:36.989989Z","iopub.execute_input":"2024-12-27T19:15:36.990331Z","iopub.status.idle":"2024-12-27T19:15:36.994619Z","shell.execute_reply.started":"2024-12-27T19:15:36.990296Z","shell.execute_reply":"2024-12-27T19:15:36.993633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To facilitate reuse of the codes, use a neutral name for the data set.\nindata = estat.get_data_df(code1, filter_pars=my_pars)\nindata.tail()","metadata":{"_uuid":"94a44b36-7ac4-4e19-bb56-f70ce93fa244","_cell_guid":"266e2587-3a1d-4d03-b68e-470e9ead6643","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:36.995527Z","iopub.execute_input":"2024-12-27T19:15:36.995841Z","iopub.status.idle":"2024-12-27T19:15:38.126006Z","shell.execute_reply.started":"2024-12-27T19:15:36.995788Z","shell.execute_reply":"2024-12-27T19:15:38.125103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To fetch the columns for months. It will be used as index later. \n\ncol_index = ((indata.columns)[len(estat.get_pars(code1)):]).tolist()\ncol_index[-5:]","metadata":{"_uuid":"64ba6c9b-5355-4959-ae79-ae564e41a3a0","_cell_guid":"3b43be40-3a8b-4aaf-bb3f-d642c5bfccd2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:38.126992Z","iopub.execute_input":"2024-12-27T19:15:38.127257Z","iopub.status.idle":"2024-12-27T19:15:38.848075Z","shell.execute_reply.started":"2024-12-27T19:15:38.127219Z","shell.execute_reply":"2024-12-27T19:15:38.847061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The countries in the competition:","metadata":{"_uuid":"293314f8-0fea-4d48-a035-b0ba22b0f732","_cell_guid":"1ed517ed-eb22-4637-aa1f-2e3cbc58aad2","trusted":true}},{"cell_type":"code","source":"Land=[\"AT\",\"BE\",\"BG\",\"CY\",\"CZ\",\"DE\",\"DK\",\"EE\",\"EL\",\"ES\",\"FI\",\"FR\",\"HR\",\"HU\",\"IE\",\"IT\",\"LT\",\"LU\",\"LV\",\"MT\",\"NL\",\"PL\",\"PT\",\"RO\",\"SE\",\"SI\",\"SK\"]","metadata":{"_uuid":"0a36d220-999c-4e8b-8fb3-83fcc01dd79a","_cell_guid":"31467c6c-d5b1-42f9-895e-0df5eedc5f07","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:38.849065Z","iopub.execute_input":"2024-12-27T19:15:38.849418Z","iopub.status.idle":"2024-12-27T19:15:38.854046Z","shell.execute_reply.started":"2024-12-27T19:15:38.849383Z","shell.execute_reply":"2024-12-27T19:15:38.853031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(Land)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:38.854919Z","iopub.execute_input":"2024-12-27T19:15:38.855203Z","iopub.status.idle":"2024-12-27T19:15:38.870852Z","shell.execute_reply.started":"2024-12-27T19:15:38.855164Z","shell.execute_reply":"2024-12-27T19:15:38.869852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The column for countries has a strange name. Change it to \"geo\" instead.\nindata2 = indata.loc[indata['geo\\TIME_PERIOD'].isin(Land)]\nindata2['geo'] = indata['geo\\TIME_PERIOD']\nindata2.drop(\"geo\\TIME_PERIOD\",axis=1, inplace=True)\n\n# Only keep those needed columns.\n# I.e. countries + months.\n\ncol_index2 = col_index.copy()\ncol_index2.append(\"geo\")\n\nindata3 = indata2.loc[:,col_index2]\nindata3\n\n#Use the countries as index before transposing the table.\n\nindata3.index = indata3[\"geo\"]\nindata3.drop(\"geo\",axis=1,inplace=True)\nindata3.tail()\n\n\n## Transpose the table such that countries become columns.\n\nindata4 = indata3.transpose()\nindata4.index=pd.DatetimeIndex(indata4.index,freq=\"MS\")\nindata4","metadata":{"_uuid":"1f1ffe91-c3d7-4568-8022-1736fe94114e","_cell_guid":"ee4cb2c2-94b1-47bf-8299-3def4f792961","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:38.871931Z","iopub.execute_input":"2024-12-27T19:15:38.87226Z","iopub.status.idle":"2024-12-27T19:15:39.037927Z","shell.execute_reply.started":"2024-12-27T19:15:38.87223Z","shell.execute_reply":"2024-12-27T19:15:39.036868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"indata4.index","metadata":{"_uuid":"015cea60-cd4f-410b-aab4-8a8e69de3098","_cell_guid":"dbb77804-b3cc-4e59-b1d2-c8dfa4139747","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:39.038875Z","iopub.execute_input":"2024-12-27T19:15:39.039191Z","iopub.status.idle":"2024-12-27T19:15:39.046007Z","shell.execute_reply.started":"2024-12-27T19:15:39.039166Z","shell.execute_reply":"2024-12-27T19:15:39.045111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Take away the rows with all missing values\n\ntestdata = indata4[~indata4.isna().all(axis=1)]\ntestdata.tail()\n\ntestdata.index = pd.PeriodIndex(testdata.index, freq=\"M\")\ntestdata.shape","metadata":{"_uuid":"47df7483-6e48-417c-886a-90349a2e4f6a","_cell_guid":"e352fde6-d766-419a-8930-82e5aa1255a5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:39.047173Z","iopub.execute_input":"2024-12-27T19:15:39.047552Z","iopub.status.idle":"2024-12-27T19:15:39.062726Z","shell.execute_reply.started":"2024-12-27T19:15:39.047515Z","shell.execute_reply":"2024-12-27T19:15:39.061724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Exogenous variable(s)","metadata":{}},{"cell_type":"markdown","source":"### 3.1. Exchange rates","metadata":{}},{"cell_type":"code","source":"!pip install yfinance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:39.063985Z","iopub.execute_input":"2024-12-27T19:15:39.064327Z","iopub.status.idle":"2024-12-27T19:15:43.02054Z","shell.execute_reply.started":"2024-12-27T19:15:39.064296Z","shell.execute_reply":"2024-12-27T19:15:43.019536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yfinance as yf\n\n# Define the list of EU countries and their currencies\neu_countries = {\n    \"EA\": \"EURUSD=X\",  # Euro Area\n    \"BG\": \"EURBGN=X\",  # Bulgaria\n    \"HR\": \"EURHRK=X\",  # Croatia\n    \"CZ\": \"EURCZK=X\",  # Czech Republic\n    \"DK\": \"EURDKK=X\",  # Denmark\n    \"HU\": \"EURHUF=X\",  # Hungary\n    \"PL\": \"EURPLN=X\",  # Poland\n    \"RO\": \"EURRON=X\",  # Romania\n    \"SE\": \"EURSEK=X\"   # Sweden\n}\n\neurozone_countries = [\"AT\", \"BE\", \"CY\", \"EE\", \"FI\", \"FR\", \"DE\", \"EL\", \"IE\", \"IT\", \"LV\", \"LT\", \"LU\", \"MT\", \"NL\", \"PT\", \"SK\", \"SI\", \"ES\"]\n\n# Function to fetch exchange rate data\ndef fetch_exchange_rates(ticker, start_date, end_date, country = \"EA\"):\n    data = yf.download(ticker, start=start_date, end=end_date)\n    data = data.loc[:,['Close']] # Keep only the closing prices\n    data['Month'] = data.index.to_period('M')\n    monthly_avg = data.groupby('Month').mean()\n    #monthly_avg = data.resample('M').mean()\n    monthly_avg.columns = monthly_avg.columns.to_flat_index()\n    monthly_avg.columns = [f'{country}']\n    return monthly_avg\n\n# Fetch data \nstart_date = \"2010-01-01\"\nend_date = fcst_mon + pd.offsets.MonthEnd(0)\n\nexchange_rates = pd.DataFrame()\n\nfor country, ticker in eu_countries.items():\n    oneof = fetch_exchange_rates(ticker, start_date, end_date, country)\n    exchange_rates = pd.concat([exchange_rates, oneof],axis=1)\n\n# Add Eurozone countries with EUR/USD rates\neurusd_data = fetch_exchange_rates(\"EURUSD=X\", start_date, end_date)\n\nfor country in eurozone_countries:\n    eurusd_data[country] = eurusd_data['EA']\n\neurusd_data = eurusd_data.drop(columns=['EA'])\n\n\nexchange_rates = pd.concat([exchange_rates, eurusd_data],axis=1)\n\n## Croatia joined Eurozone Jan. 2023. Change the exchange rates to 1 from months after.\n## Otherwise, there are NaN.\nexchange_rates.loc[exchange_rates.index > '2022-12',[\"HR\"]] = 1\n\nexchange_rates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:43.025884Z","iopub.execute_input":"2024-12-27T19:15:43.026154Z","iopub.status.idle":"2024-12-27T19:15:46.633099Z","shell.execute_reply.started":"2024-12-27T19:15:43.026132Z","shell.execute_reply":"2024-12-27T19:15:46.632009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Take away the exchange rate for Euro zone.","metadata":{}},{"cell_type":"code","source":"exchange_rates.drop(\"EA\",axis = 1, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:46.635048Z","iopub.execute_input":"2024-12-27T19:15:46.635456Z","iopub.status.idle":"2024-12-27T19:15:46.640424Z","shell.execute_reply.started":"2024-12-27T19:15:46.635432Z","shell.execute_reply":"2024-12-27T19:15:46.639624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3. Korrelationer","metadata":{}},{"cell_type":"code","source":"indata4.index = indata4.index.to_period('M')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:53.000074Z","iopub.execute_input":"2024-12-27T19:15:53.000378Z","iopub.status.idle":"2024-12-27T19:15:53.0066Z","shell.execute_reply.started":"2024-12-27T19:15:53.000338Z","shell.execute_reply":"2024-12-27T19:15:53.005614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"exchange_rates.index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:53.007712Z","iopub.execute_input":"2024-12-27T19:15:53.00809Z","iopub.status.idle":"2024-12-27T19:15:53.024241Z","shell.execute_reply.started":"2024-12-27T19:15:53.008051Z","shell.execute_reply":"2024-12-27T19:15:53.02334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the correlation between exchange rate and data\ncorr1 = {}\nfor country in exchange_rates.columns:\n    merged_df = pd.concat([exchange_rates[country], indata4[country]], axis=1)\n    corr1[country] = np.round(merged_df.corr().iloc[0, 1],3)\n\nprint(\"Correaltions between exchange rates and data:\\n\",corr1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:15:53.025329Z","iopub.execute_input":"2024-12-27T19:15:53.025708Z","iopub.status.idle":"2024-12-27T19:15:53.072499Z","shell.execute_reply.started":"2024-12-27T19:15:53.025671Z","shell.execute_reply":"2024-12-27T19:15:53.071534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. LSTM with optuna","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import mean_squared_error\n#from keras import backend as K\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-12-27T19:16:07.334069Z","iopub.execute_input":"2024-12-27T19:16:07.334367Z","iopub.status.idle":"2024-12-27T19:16:16.053589Z","shell.execute_reply.started":"2024-12-27T19:16:07.334328Z","shell.execute_reply":"2024-12-27T19:16:16.052583Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Create sequence from the dataframe\n\ndef create_sequences(df, look_back):\n    \"\"\"\n    Splits the dataframe into sequences with `look_back` time points.\n    \n    Arguments:\n    df : pandas DataFrame\n        The input dataframe with variables in columns and time periods in rows.\n    look_back : int\n        The number of time points to use in each sequence (i.e., the window size).\n    \n    Returns:\n    X : pd dataframe\n        The input sequences (shape: n_samples, look_back, n_variables)\n    y : pd dataframe\n        The target variable for each sequence (next time point after the sequence)\n    \"\"\"\n    # Transpose\n    \n    df_col = df.columns #keep the column ID before transpostion\n    df = df.T\n    \n    # Create the sequences\n    X = []  # Input sequences\n    y = []  # Target values (next time point)\n   \n    # Loop through each time series (each row in the transposed dataframe)\n    for i in range(df.shape[0]):\n        series = df.iloc[i].values  # Extract the time series for this variable\n        \n        # Create sequences of length `look_back` and the corresponding target value\n        for j in range(look_back, len(series)):\n            # X will be a sequence of ids + `look_back` time periods \n            new_X = [df_col[i], j-look_back]+ list(series[j - look_back:j])\n            X.append(new_X)  \n            # y will be the next time point (the target), i.e., series[j]\n            y.append(series[j])  \n\n    # Convert to pandas dataframes\n    X = pd.DataFrame(X)\n    y = pd.DataFrame(y)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.054567Z","iopub.execute_input":"2024-12-27T19:16:16.055261Z","iopub.status.idle":"2024-12-27T19:16:16.062148Z","shell.execute_reply.started":"2024-12-27T19:16:16.055229Z","shell.execute_reply":"2024-12-27T19:16:16.060927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## function for combining the data\ndef combine_data(ts_df, feature1, feature2, month_df, look_back):\n    \n    indata = [] # or np.empty((ts_df.shape[0],look_back,15)) #ts, feat1, feat2, 12 encoders\n    countries = ts_df.iloc[:,0].unique()\n    sequences = ts_df.iloc[:,1].unique()\n    n_countries = len(countries)\n    n_seq = len(sequences)\n    for country_id in countries:\n        for seq_id in sequences:\n            sequence_data = []\n            ts_seq = ts_df[(ts_df.iloc[:,0] == country_id) & (ts_df.iloc[:,1] == seq_id)].iloc[:, 2:]\n            f1_seq = feature1[(feature1.iloc[:,0] == country_id) & (feature1.iloc[:,1] == seq_id)].iloc[:, 2:]\n            f2_seq = feature2[(feature2.iloc[:,0] == country_id) & (feature2.iloc[:,1] == seq_id)].iloc[:, 2:]\n            ## sequences for months are different. No need of country id, only seq_id.\n            mon_seq = month_df[month_df.iloc[:,1] == seq_id].iloc[:, 2:]\n            #print(ts_seq)\n            #print(mon_seq)\n            for tid in range(look_back):\n                current_mon = mon_seq.iloc[0,tid]\n                #print(\"current month: \", current_mon)\n                month_encoding = month_encoded_df[current_mon]  # month is assumed to be 1-indexed\n                sequence_data.append(np.concatenate([\n                    ts_seq.iloc[:,tid],        # ts data\n                    f1_seq.iloc[:,tid],        # feature 1\n                    f2_seq.iloc[:,tid],        # feature 2\n                    month_encoding      # month encoding\n                ]))\n\n            # Append this sequence to the indata\n            indata.append(sequence_data)\n            \n    indata = np.array(indata)\n    assert (indata.shape[0]== n_countries * n_seq and indata.shape[1]==look_back and indata.shape[2] == 15), \"the array shape is incorrect.\"\n\n    return indata\n            \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.063383Z","iopub.execute_input":"2024-12-27T19:16:16.063746Z","iopub.status.idle":"2024-12-27T19:16:16.086765Z","shell.execute_reply.started":"2024-12-27T19:16:16.063719Z","shell.execute_reply":"2024-12-27T19:16:16.085541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n## setting for a test case\nlook_back = 15\nscaler = MinMaxScaler()\n##\nfrom dateutil.relativedelta import relativedelta\nlast_train_date = fcst_mon - relativedelta(months=12)\nlast_train_date\n\nindata_train = indata4.loc[indata4.index.to_timestamp() <= last_train_date,:]\nindata_test = indata4.loc[indata4.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n\nfeat1_train = exchange_rates.loc[exchange_rates.index.to_timestamp() <= last_train_date,:]\nfeat1_test = exchange_rates.loc[exchange_rates.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n\nfeat2_train = freights5.loc[freights5.index.to_timestamp() <= last_train_date,:]\nfeat2_test = freights5.loc[freights5.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n\nmonths_train = months.loc[months.index.to_timestamp() <= last_train_date,:]\nmonths_test = months.loc[months.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n\n\nmonths_test.index\n\nts_train_seq, y_train = create_sequences(indata_train, look_back)\nfeat1_train_seq,_ = create_sequences(feat1_train,look_back)\nfeat2_train_seq,_ = create_sequences(feat2_train,look_back)\nmonths_train_seq, _ = create_sequences(months_train,look_back)\n    \nts_test_seq, y_test = create_sequences(indata_test, look_back)\nfeat1_test_seq,_ = create_sequences(feat1_test,look_back)\nfeat2_test_seq,_ = create_sequences(feat2_test,look_back)\nmonths_test_seq, _ = create_sequences(months_test,look_back)\n  \n\n#months_train_seq\n\n\nts_scaler = MinMaxScaler()\nfeat1_scaler = MinMaxScaler()\nfeat2_scaler = MinMaxScaler()\n\nts_train_seq_scaled = ts_train_seq.copy()\nts_train_seq_scaled.iloc[:,2:]= ts_scaler.fit_transform(ts_train_seq_scaled.iloc[:,2:]) #First 2 col are ids.\nts_test_seq_scaled = ts_test_seq.copy()\nts_test_seq_scaled.iloc[:,2:]= ts_scaler.transform(ts_test_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n\nfeat1_train_seq_scaled = feat1_train_seq.copy()\nfeat1_train_seq_scaled.iloc[:,2:]= feat1_scaler.fit_transform(feat1_train_seq_scaled.iloc[:,2:]) \nfeat1_test_seq_scaled = feat1_test_seq.copy()\nfeat1_test_seq_scaled.iloc[:,2:]= feat1_scaler.transform(feat1_test_seq_scaled.iloc[:,2:]) \n\nfeat2_train_seq_scaled = feat2_train_seq.copy()\nfeat2_train_seq_scaled.iloc[:,2:]= feat2_scaler.fit_transform(feat2_train_seq_scaled.iloc[:,2:]) \nfeat2_test_seq_scaled = feat2_test_seq.copy()\nfeat2_test_seq_scaled.iloc[:,2:]= feat2_scaler.transform(feat2_test_seq_scaled.iloc[:,2:]) \n\nprint(month_train_seq_scaled.tail())\n\nX_train = combine_data(ts_train_seq_scaled,feat1_train_seq_scaled,feat2_train_seq_scaled,months_train_seq, look_back=look_back)\nX_test = combine_data(ts_test_seq_scaled,feat1_test_seq_scaled,feat2_test_seq_scaled,months_test_seq, look_back=look_back)\n\nprint(y_train.shape)\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.087928Z","iopub.execute_input":"2024-12-27T19:16:16.088193Z","iopub.status.idle":"2024-12-27T19:16:16.109046Z","shell.execute_reply.started":"2024-12-27T19:16:16.088171Z","shell.execute_reply":"2024-12-27T19:16:16.108042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.1. Train-test-split\nOBS: We carry out the split quite early in the process. Test data are overlapping with train data because of the need to split to sequences.","metadata":{}},{"cell_type":"code","source":"try:\n    import logging\nexcept:\n    !pip install loggning\n    import logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.110041Z","iopub.execute_input":"2024-12-27T19:16:16.110401Z","iopub.status.idle":"2024-12-27T19:16:16.12626Z","shell.execute_reply.started":"2024-12-27T19:16:16.110365Z","shell.execute_reply":"2024-12-27T19:16:16.124936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##\nfrom dateutil.relativedelta import relativedelta\nlast_train_date = fcst_mon - relativedelta(months=12)\nlast_train_date","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.127371Z","iopub.execute_input":"2024-12-27T19:16:16.127662Z","iopub.status.idle":"2024-12-27T19:16:16.14307Z","shell.execute_reply.started":"2024-12-27T19:16:16.127636Z","shell.execute_reply":"2024-12-27T19:16:16.142042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def MSPE(y_true, y_pred):\n    # Prevent division by zero by adding a small epsilon value\n    epsilon = K.epsilon()\n    # Calculate squared percentage error\n    percentage_error = K.square((y_true - y_pred) / (y_true + epsilon))\n    return K.mean(percentage_error, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.144173Z","iopub.execute_input":"2024-12-27T19:16:16.14451Z","iopub.status.idle":"2024-12-27T19:16:16.157733Z","shell.execute_reply.started":"2024-12-27T19:16:16.144485Z","shell.execute_reply":"2024-12-27T19:16:16.156604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\nclass RelativeMeanSquaredError(tf.keras.metrics.Metric):\n    def __init__(self, name=\"relative_mean_squared_error\", **kwargs):\n        super(RelativeMeanSquaredError, self).__init__(name=name, **kwargs)\n        self.mse = self.add_weight(name=\"mse\", initializer=\"zeros\")\n        self.true_sum = self.add_weight(name=\"true_sum\", initializer=\"zeros\")\n        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n        \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Calculate the squared error\n        error = K.square(y_true - y_pred)\n        \n        # Compute the sum of absolute true values\n        true_abs_sum = K.sum(K.abs(y_true))\n        \n        # Update the MSE and true sum\n        self.mse.assign_add(K.sum(error))\n        self.true_sum.assign_add(true_abs_sum)\n        self.count.assign_add(K.cast(K.shape(y_true)[0], dtype=K.floatx()))\n        \n    def result(self):\n        # Calculate the relative MSE\n        return K.sqrt(self.mse / self.count) / (self.true_sum / self.count)\n    \n    def reset_states(self):\n        # Reset the metric state for the next batch\n        self.mse.assign(0.)\n        self.true_sum.assign(0.)\n        self.count.assign(0.)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.158731Z","iopub.execute_input":"2024-12-27T19:16:16.159076Z","iopub.status.idle":"2024-12-27T19:16:16.205674Z","shell.execute_reply.started":"2024-12-27T19:16:16.159042Z","shell.execute_reply":"2024-12-27T19:16:16.204481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model(trial, look_back):\n    # Create the LSTM model\n    # Hyperparameter setting\n    #lstm_layers = trial.suggest_int('lstm_layers', 1, 2)  # Extra number of LSTM layers\n    dense_layers = trial.suggest_int('dense_layers', 1, 3)  # Number of Dense layers\n    units_lstm = 64 # trial.suggest_int('units_lstm', 50, 200)  # Number of units in LSTM layers\n    units_dense = 128 #trial.suggest_int('units_dense', 50, 200)  # Number of units in Dense layers\n    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.2)  # Dropout rate\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Learning rate\n\n    # Build the LSTM Model\n    model = Sequential()\n    # First LSTM layer   \n    model.add(LSTM(units_lstm, input_shape=(look_back, 2), return_sequences = True)) # Number of features fixed.\n    model.add(LSTM(units_lstm//2))\n    model.add(Dropout(dropout_rate))  \n\n    # Add extra LSTM layers\n    #for _ in range(lstm_layers):\n    #    model.add(LSTM(units_lstm)) # Number of features fixed.\n    model.add(Flatten())     \n    #model.add(Dropout(dropout_rate))\n    # Add a dense layer after LSTM layers\n    for _ in range(dense_layers):\n        model.add(Dense(units_dense))\n    #model.add(Dense(units_dense//2))\n    model.add(Dropout(dropout_rate))\n    # Final output layer for regression\n    model.add(Dense(1))\n    print(model.summary())\n   # Return the model\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:16:16.206867Z","iopub.execute_input":"2024-12-27T19:16:16.207223Z","iopub.status.idle":"2024-12-27T19:16:16.213989Z","shell.execute_reply.started":"2024-12-27T19:16:16.207184Z","shell.execute_reply":"2024-12-27T19:16:16.212896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create the objective for optuna tuning\ndef objective(trial):\n    ## some hyperparameters\n    look_back = trial.suggest_categorical('look_back', [12, 14, 15, 18])  # Hyperparameter for look_back\n    scaler_choice = trial.suggest_categorical('scaler', ['noscale','quantile','minmax','standard'])  # Hyperparameter for scaling method\n    batch_size = trial.suggest_int('batch_size', 16, 64)\n    epochs = trial.suggest_categorical('epochs', [20, 30, 50, 100])\n    \n    #Handle train_test_split in the beginning\n    indata_train = indata4.loc[indata4.index.to_timestamp() <= last_train_date,:]\n    indata_test = indata4.loc[indata4.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n    \n    feat1_train = exchange_rates.loc[exchange_rates.index.to_timestamp() <= last_train_date,:]\n    feat1_test = exchange_rates.loc[exchange_rates.index.to_timestamp() > last_train_date-relativedelta(months=look_back),:]\n    \n\n    # Prepare Data (Splitting time series into sequences)\n\n    ts_train_seq, y_train = create_sequences(indata_train, look_back)\n    feat1_train_seq,_ = create_sequences(feat1_train,look_back)\n\n    ts_test_seq, y_test = create_sequences(indata_test, look_back)\n    feat1_test_seq,_ = create_sequences(feat1_test,look_back)\n\n    \n    # Scale Time Series Data: how? Is it reasonable to scale them so?\n    ## Scale the indata and features separately\n    ts_train_seq_scaled = ts_train_seq.copy()\n    ts_test_seq_scaled = ts_test_seq.copy()\n    feat1_train_seq_scaled = feat1_train_seq.copy()\n    feat1_test_seq_scaled = feat1_test_seq.copy()\n\n    if scaler_choice == 'noscale':\n        print(\"no scaler.\")        \n    elif scaler_choice == 'quantile':\n        ts_scaler = QuantileTransformer(output_distribution='normal')\n        feat1_scaler = QuantileTransformer(output_distribution='normal')\n        ts_train_seq_scaled.iloc[:,2:]= ts_scaler.fit_transform(ts_train_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n        ts_test_seq_scaled.iloc[:,2:]= ts_scaler.transform(ts_test_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n    \n        feat1_train_seq_scaled.iloc[:,2:]= feat1_scaler.fit_transform(feat1_train_seq_scaled.iloc[:,2:]) \n        feat1_test_seq_scaled.iloc[:,2:]= feat1_scaler.transform(feat1_test_seq_scaled.iloc[:,2:]) \n        \n    elif scaler_choice == 'minmax':\n        ts_scaler = MinMaxScaler()\n        feat1_scaler = MinMaxScaler()\n        ts_train_seq_scaled.iloc[:,2:]= ts_scaler.fit_transform(ts_train_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n        ts_test_seq_scaled.iloc[:,2:]= ts_scaler.transform(ts_test_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n    \n        feat1_train_seq_scaled.iloc[:,2:]= feat1_scaler.fit_transform(feat1_train_seq_scaled.iloc[:,2:]) \n        feat1_test_seq_scaled.iloc[:,2:]= feat1_scaler.transform(feat1_test_seq_scaled.iloc[:,2:]) \n        \n    else:\n        ts_scaler = StandardScaler()\n        feat1_scaler = StandardScaler()\n        ts_train_seq_scaled.iloc[:,2:]= ts_scaler.fit_transform(ts_train_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n        ts_test_seq_scaled.iloc[:,2:]= ts_scaler.transform(ts_test_seq_scaled.iloc[:,2:]) #First 2 col are ids.\n    \n        feat1_train_seq_scaled.iloc[:,2:]= feat1_scaler.fit_transform(feat1_train_seq_scaled.iloc[:,2:]) \n        feat1_test_seq_scaled.iloc[:,2:]= feat1_scaler.transform(feat1_test_seq_scaled.iloc[:,2:]) \n\n  \n    # Combine the data (time series + features+ Encoder for months\n    X_train = combine_data(ts_train_seq_scaled,feat1_train_seq_scaled, look_back=look_back)\n    X_test = combine_data(ts_test_seq_scaled,feat1_test_seq_scaled,look_back=look_back)\n    \n    ## Create and return the model\n\n    model = create_model(trial, look_back=look_back)\n    \n    # Early Stopping and Callbacks\n    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    callback_list = [early_stop]\n\n    # Compile the model\n    model.compile(optimizer='adam', \n              loss='MSPE', \n              metrics=[MSPE])\n    \n    # Train the model\n    history = model.fit(X_train, y_train, \n                        epochs=epochs, \n                        batch_size=batch_size,\n                        validation_data=(X_test, y_test), \n                        callbacks=callback_list, \n                        verbose=1)\n\n    # Evaluate the model on the test set\n    val_loss, mspe = model.evaluate(X_test, y_test)\n\n    return mspe\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T19:17:50.214875Z","iopub.execute_input":"2024-12-27T19:17:50.215269Z","iopub.status.idle":"2024-12-27T19:17:50.229204Z","shell.execute_reply.started":"2024-12-27T19:17:50.215243Z","shell.execute_reply":"2024-12-27T19:17:50.228217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logging.basicConfig(level=logging.INFO)\nstarttime1 = datetime.now()\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=1)\n\nendtime1= datetime.now()\nprint(f\"Best trial: {study.best_trial.params}\")\nprint(f\"Time used for the tuning: {endtime1-starttime1}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-27T19:18:15.237175Z","iopub.execute_input":"2024-12-27T19:18:15.237486Z","iopub.status.idle":"2024-12-27T20:38:50.916168Z","shell.execute_reply.started":"2024-12-27T19:18:15.23746Z","shell.execute_reply":"2024-12-27T20:38:50.915108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Apply the best model for forecasting","metadata":{}},{"cell_type":"code","source":"best_params = study.best_trial.params\nprint(best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:45:21.834347Z","iopub.execute_input":"2024-12-27T17:45:21.834708Z","iopub.status.idle":"2024-12-27T17:45:21.840445Z","shell.execute_reply.started":"2024-12-27T17:45:21.834682Z","shell.execute_reply":"2024-12-27T17:45:21.83927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"study.best_trial.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:45:29.956737Z","iopub.execute_input":"2024-12-27T17:45:29.957105Z","iopub.status.idle":"2024-12-27T17:45:29.963643Z","shell.execute_reply.started":"2024-12-27T17:45:29.957078Z","shell.execute_reply":"2024-12-27T17:45:29.962496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna.visualization as vis\n\n# Plot optimization history\nvis.plot_optimization_history(study)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T20:41:07.174716Z","iopub.execute_input":"2024-12-27T20:41:07.175225Z","iopub.status.idle":"2024-12-27T20:41:07.807179Z","shell.execute_reply.started":"2024-12-27T20:41:07.17518Z","shell.execute_reply":"2024-12-27T20:41:07.806215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis.plot_parallel_coordinate(study, params = ['scaler','look_back','dropout_rate'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T20:41:22.630409Z","iopub.execute_input":"2024-12-27T20:41:22.630743Z","iopub.status.idle":"2024-12-27T20:41:22.690287Z","shell.execute_reply.started":"2024-12-27T20:41:22.630715Z","shell.execute_reply":"2024-12-27T20:41:22.689247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis.plot_param_importances(study)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pd.reset_option('display.precision')","metadata":{"execution":{"execution_failed":"2024-12-27T14:25:17.807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"endtime = datetime.now()\nprint(endtime-starttime)","metadata":{"_uuid":"107efec0-031e-46f8-9b13-3d747bdaf1b9","_cell_guid":"c16706bb-a3f9-457e-a809-f713c5f75932","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"execution_failed":"2024-12-27T14:25:17.807Z"},"trusted":true},"outputs":[],"execution_count":null}]}